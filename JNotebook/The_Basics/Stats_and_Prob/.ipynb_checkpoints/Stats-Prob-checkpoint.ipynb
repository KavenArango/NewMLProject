{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics and Probability\n",
    "This is a new section of the \"foundational\" knowledge that we need to go deeper into Business Analytics/Data Science. Obviously Statistics, Probability, Mathematics are vast areas of their own. We will revisit only the concepts that we will need for the future sections on Descriptive, Predictive and Prescriptive Analytics.\n",
    "\n",
    "Where appropriate, we will provide a forward reference of a concept to the future section where the concept will be used. Conversely in the future sections we will provide a backward reference to these core concepts.\n",
    "\n",
    "An example is: \n",
    " * We will revisit the concepts of **Conditional Probability and Bayes' Theorm of conditional probablity**. We will use these concepts (Bayes' Theorem) in developing **Naive Bayes Classification Model** to predict classification of an outcome based on a set of input variables in the section on **Predictive Analytics**\n",
    "\n",
    "Real life application of Naive Bayes Classification are:\n",
    "* Classifying an email as **spam** based on the presence of a set of key words\n",
    "* Classifying an insurance claim as valid or fraudulent based some attributes of the claim in **fraud detection**\n",
    "* etc.\n",
    "\n",
    "\n",
    "## Mean, Grand Mean (Mean-of-Means), introduction to ANOVA\n",
    "The **Mean** of a collection of numbers is the average value of the collection of numbers. The **Mean** is the **sum** of all the numbers in the collection divided by the count of numbers of the collection.\n",
    "\n",
    "In case there are **multiple** collections of numbers and you want to do some **analysis** of all the collections and see if one of the collection of numbers **significantly** different form other collections of numbers and verify such **hypothesis** you can use a technique called **Analysis of Variance** also called **ANOVA**. \n",
    "\n",
    "**ANOVA** is a statistical process, widely used in **Descriptive Analytics**. One of the steps of **ANOVA** is to calculate the **Grand Mean or the Mean of Means** of multiple samples of data.\n",
    "\n",
    "We will study **ANOVA** in details in **Descriptive Analytics** section.\n",
    "\n",
    "Couple of simple Python function to calculate the **Mean** and **Grand Mean** of a set of samples is below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual lists are  [23, 45, 67, 11, 89, 234] , [12, 55, 73, 11, 109, 234] , [67, 45, 84, 9, 87, 268]\n",
      "List of Lists =  [[23, 45, 67, 11, 89, 234], [12, 55, 73, 11, 109, 234], [67, 45, 84, 9, 87, 268]]\n",
      "List of means =  [78.17, 82.33, 93.33]\n",
      "Mean of Means or Grand Mean =  84.61\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def mean(x):\n",
    "    return round((sum(x) / len(x)), 2)\n",
    "\n",
    "def mean_of_means(x):\n",
    "    list_of_mean = [round((mean(x_i)), 2) for x_i in x]\n",
    "    return mean(list_of_mean)\n",
    "\n",
    "# =================== Example of calculation of Mean and Grand Mean of several samples ========================\n",
    "\n",
    "x1 = [23, 45, 67, 11, 89, 234]\n",
    "x2 = [12, 55, 73, 11, 109, 234]\n",
    "x3 = [67, 45, 84, 9, 87, 268]\n",
    "\n",
    "list_of_lists = [x1, x2, x3]\n",
    "list_of_mean = [round((mean(x_i)), 2) for x_i in list_of_lists]\n",
    "m_of_m = mean_of_means (list_of_lists)\n",
    "\n",
    "print('Individual lists are ', x1,',', x2, ',', x3)\n",
    "print('List of Lists = ', list_of_lists)\n",
    "print('List of means = ', list_of_mean)\n",
    "print('Mean of Means or Grand Mean = ', m_of_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersion, Deviation, Variance and Standard Deviation of a Data Sample\n",
    "**Dispersion** is the measure of **how spread out the data is** in the Data Sample. It is the difference between the **Maximum Value** and the **Minimum Value** of the Data Sample.\n",
    "\n",
    "Another measure of the **spread of the data** in a Data Sample is the **Deviation** which is the list of the difference of each data point from the Mean of the Data Sample. In **Regression Analysis** (which we will learn in details later) they are also called the **Errors** or **Residuals**.\n",
    "\n",
    "The **Deviations** can be positive or negative. So the sum of Deviations of very spread out data can be close to zero. This can give the wrong impression that the data is NOT widely spread out because its **Deviation**  is zero or close to zero.\n",
    "\n",
    "***--> create math notations***\n",
    "\n",
    "To counter this problem, the most widely used measure of the **spread of the data** in a Data Sample is the**Variance** of a Data Sample which is the **sum of squares of the deviations** of each data points from the Mean of the Data, divided by **(n-1)**, where **n is the sample size**.\n",
    "\n",
    "***--> create math notations***\n",
    "\n",
    "Another measure of the **spread of the data in a sample** is the **Standard Deviation**. Standard Deviation is the **square root** of the **Variance** of the data in the sample.\n",
    "\n",
    "**Dispersion, Deviation and Variance** of a Data Sample can be easily calculated as follows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data =  [2, 27, 48, 99, 348, 587, 439, 567, 602]\n",
      "================================================\n",
      "Dispersion of Input Data =  600\n",
      "===================================================\n",
      "Diff from mean of Input Data =  [-300.11, -275.11, -254.11, -203.11, 45.89, 284.89, 136.89, 264.89, 299.89]\n",
      "===================================================\n",
      "Deviation of Input Data =  0.01\n",
      "===================================================\n",
      "Variance of Input Data =  66710.61\n",
      "===================================================\n",
      "Standard Deviation of Input Data =  258.28\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "input_data = [2, 27, 48, 99, 348, 587, 439, 567, 602]\n",
    "\n",
    "print('Input Data = ', input_data)\n",
    "print('================================================')\n",
    "\n",
    "def data_range(x):\n",
    "    return max(x) - min(x)\n",
    "print('Dispersion of Input Data = ', data_range(input_data))\n",
    "print('===================================================')\n",
    "def diff_from_mean(x):\n",
    "    x_bar = mean(x)\n",
    "    return [round((x_i - x_bar), 2) for x_i in x]\n",
    "print('Diff from mean of Input Data = ', diff_from_mean(input_data))\n",
    "print('===================================================')\n",
    "\n",
    "print('Deviation of Input Data = ', round(sum(diff_from_mean(input_data)), 4))\n",
    "print('===================================================')\n",
    "\n",
    "def sum_of_squares(x):\n",
    "    return(sum(x_i**2 for x_i in x))\n",
    "\n",
    "def variance(x):\n",
    "    l = len(x)\n",
    "    deviations = diff_from_mean(x)\n",
    "    return (sum_of_squares(deviations)/(l - 1))\n",
    "print('Variance of Input Data = ', round(variance(input_data), 2))\n",
    "print('===================================================')\n",
    "\n",
    "def standard_deviation(x):\n",
    "    v = variance(x)\n",
    "    return math.sqrt(v)\n",
    "print('Standard Deviation of Input Data = ', round(standard_deviation(input_data), 2))\n",
    "print('===================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Hypothesis Testing\n",
    "### Null and Alternate Hypothesis\n",
    "Statistical **Hypothesis Testing** is making an assumption (hypothesis) and testing with the test data to see if the assumption was correct or incorrect. Every hypothesis test, regardless of the data population and other parameters involved, requires the three steps below.\n",
    "* Making an initial assumption.\n",
    "* Collecting evidence (data).\n",
    "* Based on the available evidence (data), deciding whether to reject or not reject the initial assumption.\n",
    "\n",
    "The initial assumption made is called **Null Hypothesis (H-0)** and the alternative (opposite) to the **Null Hypothesis** is called the **Alternate Hypothesis (H-A)**\n",
    "\n",
    "Two widely used approach to **hypothesis testing** are\n",
    "* Critical value approach\n",
    "* p-value approach\n",
    "\n",
    "The **Critical value** approach involves comparing the observed test statistic to some cutoff value, called the **Critical Value**. If the test statistic is more extreme (i.e. more than the **Upper Critical Value** or less than the **Lower Critical Value**) than the **Critical Value**, then the null hypothesis is rejected in favor of the alternative hypothesis. If the test statistic is not as extreme as the critical value, then the null hypothesis is not rejected.\n",
    "\n",
    "The **p-value** approach involves determining the probability of observing a more extreme test statistics in the direction of **Alternate Hypothesis**, assuming the null hypothesis were true. \n",
    "\n",
    "If the **p-value** is less than (or equal to) **α (the accepted level of p-value)**, then the null hypothesis **is rejected** in favor of the alternative hypothesis. If the P-value is greater than **α (the critical value)**, then the null hypothesis **is not rejected**.\n",
    "\n",
    "### Z-Score and p-Value\n",
    "In this section we are just learning the definitions of **Z-Score** and **p-Value** and their inter-relations. In a subsequent section we will use the Z-Score, p-value along with **Level of Confidence** or **Level of Significance** to test a hypothesis (i.e. Reject (i.e. the Alternate Hypothesis is acceptedas the new norm. the Null Hypothesis or Fail to Reject the Null Hypothesis (i.e. Null Hypothesis remains valid)\n",
    "\n",
    "A **Z-Score** of a sample of data is a score that expresses the value of a distribution in standard deviation with respect to the mean. It shows how far (**how many Standard Deviation**) a specific value of data is from the sample **Mean**.\n",
    "Z-Score is calcualted by the formula\n",
    "\n",
    "**z = (X - X-bar)/Std-dev**\n",
    "\n",
    "where \n",
    "\n",
    "X = a Data Value\n",
    "\n",
    "X-bar = Sample Mean\n",
    "      \n",
    "Std-dev = Standard Deviation of the sample\n",
    "\n",
    "**p-value** of a Data Value is the probability of obtaining a sample data that is \"more extreme* than the ones observed in your data assuming the Null Hypothesis is true.\n",
    "\n",
    "The p-value of a z-score can be obtained from a Statistical Z-Table or using a Python Library function. Here we will use the Python Library function.\n",
    "\n",
    "**p-value = stats.norm.cdf(z-score)**\n",
    "\n",
    "However, depending on the data we are trying to test (in the case 53) compared to the currently known data (National Average = 60, Standard Deviation = 3) we may have to use a slightly different formula. Do do that we need to learn the **Left Tail** and **Right Tail** tests.\n",
    "\n",
    "### Left-Tail, Right-Tail and Two-Tail Tests of Hypothesis\n",
    "If the data we are trying to test (53) is **less than** the **Mean** (60) we use the **Left Tail Test**. If the data (say the class average was 68 as opposed to 53) is **greater than** the **Mean** (60), we use the **Right Tail Test**.\n",
    "\n",
    "For a **Right Tail Test** the formula for p-value (again using a Python Library function) is\n",
    "\n",
    "**p-value =  1- stats.norm.cdf(z-score)**\n",
    "\n",
    "***p-value for a z-score can be looked up from the Statistical Z-Table***\n",
    "\n",
    "#### An Example of Z-Score and p-value\n",
    "Assume that we have the scores of a test in Business Analytics in a class of 100. The Mean of the sample (100 test scores) is 53. The National Average of the same test is 60 with a Standard Deviation of 3. We want to calculate the Z-score and p-value for this class sample (Average is 53) with respect to the National data (Average = 60, Standard Deviation = 3) to test our hypothesis \"the class score is similar to the National Average\"\n",
    "\n",
    "Here we will calculate the z-score and corresponding p-value for Case-1 where the **class average is 53** and Case-2 where the **class average is 66**\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Example of a Left Tail Test ============\n",
      "Class score mean =  53\n",
      "Zscore for mean class score (53) =  -2.33\n",
      "p-value for the mean class score (53) =  0.009903\n",
      "========== Example of a Right Tail Test ============\n",
      "Class score mean =  66\n",
      "Zscore for mean class score (66) =  2.0\n",
      "p-value for the mean class score (66) =  0.02275\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Example of a Left Tail Test\n",
    "print('========== Example of a Left Tail Test ============')\n",
    "# Case-1 where class score mean = 53\n",
    "print('Class score mean = ', 53)\n",
    "# Calculating the z-score of 53 with respect to the National Score (Mean = 60, S-Dev = 3)\n",
    "zscore1 = round((53 - 60)/3, 2)\n",
    "print('Zscore for mean class score (53) = ', zscore1)\n",
    "# Since 53 is less than the national average 60 we will do the Left Tail Test\n",
    "prob1 = round(stats.norm.cdf(zscore1), 6)\n",
    "print('p-value for the mean class score (53) = ',  prob1)\n",
    "\n",
    "# Example of a Right Tail Test\n",
    "print('========== Example of a Right Tail Test ============')\n",
    "# Case-2 where class score mean = 68\n",
    "print('Class score mean = ', 66)\n",
    "# Calculating the z-score of 68 with respect to the National Score (Mean = 60, S-Dev = 3)\n",
    "zscore2 = round((66 - 60)/3, 2)\n",
    "print('Zscore for mean class score (66) = ', zscore2)\n",
    "# Since 68 is more than the national average 60 we will do the Right Tail Test\n",
    "prob2 = round(1 - stats.norm.cdf(zscore2), 6)\n",
    "print('p-value for the mean class score (66) = ',  prob2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level of Confidence and Level of Significance\n",
    "Since the results of statistical test are not **definete proof** of the conclusion, the results are always associsated with a **Level of Confidence** or a **Livel of Significance**. Normally we would strive for a high **Level of Confidence**  or a statistically significant result with high **Level of Significance** when we are testing if a Null Hypothesis is true or the Alternate Hypothesis should replace the Null Hypothesis.\n",
    "\n",
    "Usually the **Level of Confidence (C)** used are 95% (0.95), 99% (0.99) etc. for the conclusions of a hypothesis testing to be considered **\"reliable\"**. **Level of Significance** is the inverse of Level of Confidence, i.e. \n",
    "\n",
    "**Level of Significance = 1 - Level of Confidence** or S = 1- C. For Level of Confidence of 99% (0.99) the Level of Significance is 0.01 and for the Level of Confidence of 95% (0.95), the Level of Significance is 0.05.\n",
    "\n",
    "In majority of hypothesis tests a Level of Significance of 0.05 is used. This is called the **Critical Value α** to test the p-value (calculated in the previous step)\n",
    "\n",
    "If the p-value is **less than** the **Critical Value α**, the test results are considered as \"highly significant**. **Critical Value α = 0.01**, by the same token is considered as \"very highly significant\".\n",
    "\n",
    "### Hypothesis Testing Using Z-Score, p-Value and Level of Significance\n",
    "In a hypothesis test using -Score and p-value, if the p-value is less than **Critical Value α** (0.05 in our case), the test is considered statistically highly significant and Alternate Hypothesis is accepted and the Null Hypothesis is rejected and vice versa.\n",
    "\n",
    "In our test case-1 where the mean class score is 53, the p-value is 0.00993 which is less than the Critical Value α (0.05), the Null Hypothesis, that the mean marks of the class is similar to the national average is **Rejected**\n",
    "\n",
    "In test case-2 where the mean class score is 66, the p-value is 0.02275 which is more than the Critical Value α (0.05), the Null Hypothesis, that the mean marks of the class is similar to the national average is **Accepted/Retained**\n",
    "\n",
    "A Two-Tailed test can also be used in the above case using the same concepts of Z-Score, p-value and α, the Critical Significance Level. We will discuss Hypothesis Testing in more details in the **Descriptive Analytics** section.\n",
    "\n",
    "### Getting p-value from z-score and z-score from p-value\n",
    "We have already used **stats.norm.cdf(zscore1)** to get p-value from z-score\n",
    "\n",
    "***p-value = stats.norm.cdf(zscore1)***\n",
    "\n",
    "Now we will use stats.norm.ppf(p-value) to get z-score from p-value\n",
    "\n",
    "***z-score = stats.norm.ppf(c-value), remembering, p-value = 1 - c-value***\n",
    "\n",
    "Let us calculate z-score for the most commonly used **Confidence Levels (C)** of 90% (0.9), 95% (0.95), 98% (0.98) and 99% (0.99), i.e. the most commonly used **Significance Levels (S)** of 0.1, 0.05, 0.02 and 0.01 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2815515655446004\n",
      "1.6448536269514722\n",
      "2.0537489106318225\n",
      "2.3263478740408408\n",
      "===================================================================\n",
      "1.6448536269514722\n",
      "1.959963984540054\n",
      "2.3263478740408408\n",
      "2.5758293035489004\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "z_score_1 = stats.norm.ppf(0.9) # for C= 0.9 i.e. p = 0.1\n",
    "print(z_score_1)\n",
    "z_score_2 = stats.norm.ppf(0.95) # for C= 0.95 i.e. p = 0.05\n",
    "print(z_score_2)\n",
    "z_score_3 = stats.norm.ppf(0.98) # for C= 0.98 i.e. p = 0.02\n",
    "print(z_score_3)\n",
    "z_score_4 = stats.norm.ppf(0.99) # for C= 0.99 i.e. p = 0.01\n",
    "print(z_score_4)\n",
    "# For 2-tail test the corresponding z-scores are (+-)1.645, 1.96, 2.33 and 2.575 respectively (show calc with α/2 )\n",
    "print(\"===================================================================\")\n",
    "z_score_5 = stats.norm.ppf(0.95) # for C= 0.95 i.e. p = 0.05 on each tail\n",
    "print(z_score_5)\n",
    "z_score_6 = stats.norm.ppf(0.975) # for C= 0.975 i.e. p = 0.025 on each tail\n",
    "print(z_score_6)\n",
    "z_score_7 = stats.norm.ppf(0.99) # for C= 0.99 i.e. p = 0.01 on each tail\n",
    "print(z_score_7)\n",
    "z_score_8 = stats.norm.ppf(0.995) # for C= 0.995 i.e. p = 0.005 on each tail\n",
    "print(z_score_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Scenarios of Different Types of Hypothesis Tests\n",
    "#### Example - 1\n",
    "\n",
    "*** A company has stated that they make straw machine that makes straws that are 4 mm in diameter. A worker belives that the machine no longer makes straws of this size and samples 100 straws to perform a hypothesis test with 99% Confidence level. Write the null and alternate hypothesis and any other related data.***\n",
    "\n",
    "                   H-0: µ = 4 mm H-a: µ != 4 mm n = 100, C = 0.99, Critical Value α = 1 - C = 0.01 \n",
    "\n",
    "#### Example - 2\n",
    "*** Doctors believe that the average teen sleeps on average no longer than 10 hours per day. A researcher belives that the teens sleep longer. Write the H-0 and H-a***\n",
    "\n",
    "                   H-0: µ <= 10   H-a: µ > 10\n",
    "                   \n",
    "#### Example - 3\n",
    "*** The school board claims that at least 60% of students bring a phone to school. A teacher believes this number is too high and randomly samples 25 students to test at a Significance Level of 0.02. Write the H-0, H-a and other related informations***\n",
    "\n",
    "                  H-0: p >= 0.60  H-a: p < 0.60  n = 25  Critical Value α = 0.02   C = 1 - α = 1- 0.02 = 0.98 (98%)\n",
    "                  \n",
    "With the available information, it is possible to write the **null** and **alternate** hypotheses, but in these examples we do not have enough information to test them.\n",
    "\n",
    "Recall the steps of hypothesis tests outlined above\n",
    "\n",
    "* Write the hypotheses H-0 and H-a\n",
    "* Given µ, standard deviation calculate the z-score for the number to be tested using formula z = (X-bar - µ)/Std-dev\n",
    "* Calculate the p-value using the python function p-value = 1- stats.norm.cdf(z-score)\n",
    "* Given Significance Level Critical Value α or given Confidence Level calculate Critical Value α = 1-C\n",
    "* For **Left Tail** test use the p-value calculated\n",
    "* For **Right Tail Test** p-value = 1- (calculated p-value)\n",
    "* For **Two Tail Test** compare the calculated p-vlaue with  α/2\n",
    "* If the calculated p-value is **less** than Critical Value α, **reject** Null Hypothesis else **fail to reject** the Null Hypothesis\n",
    "\n",
    "***Note: If H-a has <, it is a Left Tail Test, if H-a has >, it is a Right Tail Test, if H-a has != it is a 2-Tail Test***\n",
    "\n",
    "So, to be able to test the hypothesis we need to have x (the value to be tested), x-bar (sample mean), std-dev (sample standard deviation, required Confidence Level or the required Significance Level.\n",
    "\n",
    "In the next example we will go through these steps (assuming all the necessary information are given)\n",
    "\n",
    "#### Example - 4\n",
    "Records show that students on average score less than or equal to 850 on a test. A test prep company says that the students who take their course will score higher than this. To test, they sample 1000 students who score on an average of 856 with a standard deviation of 98 after taking the course. At 0.05 Significance Level, test the company claim.\n",
    "\n",
    "            H-0: µ <= 850  H-a: µ > 850  n = 1000  x-bar = 856  std-dev = 98  α = 0.05 (C = 0.95 or 95%)\n",
    "       \n",
    "Let's calculate the z-score and p-value to test the hypothesis. It is a **Right Tail Test**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score =  0.061224489795918366\n",
      "p-value =  0.4755902131389005\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "x_bar = 856\n",
    "µ = 850\n",
    "s_dev = 98\n",
    "z_score = (x_bar - µ)/s_dev\n",
    "print(\"Z-score = \", z_score)\n",
    "p_value = (1 - norm.cdf(z_score)) # since it is a Right Tail test\n",
    "print(\"p-value = \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Since the calculated p-value is greater than α (0.05) we fail to reject  the null hypothesis, i.e. company claim is invalid or NOT Statistically Significant***\n",
    "\n",
    "#### Example - 5\n",
    "A newspaper reports that the average age a woman gets married is 25 years or  less. A researcher thinks that the average age is higher. He samples 213 women and gets an average of 25.4 years with standard deviation of 2.3 years. With 95% Confidence Level, test the researcher's claim.\n",
    "\n",
    "Let's calculate the z-score and p-value to test the hypothesis. It is a **Right Tail Test**\n",
    "\n",
    "\n",
    "        H-0: µ <= 25  H-a: µ > 25  n = 213  x-bar = 25.4  s-dev = 2.3  C = 95% = 0.95  α = 0.05\n",
    "\n",
    "Let's calculate the z-score and p-value to test the hypothesis. It is a **Right Tail Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score =  0.17391304347826025\n",
      "p-value =  0.43096690081487876\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "x_bar = 25.4\n",
    "µ = 25\n",
    "s_dev = 2.3\n",
    "z_score = (x_bar - µ)/s_dev\n",
    "print(\"Z-score = \",z_score)\n",
    "\n",
    "p_value = (1 - stats.norm.cdf(z_score)) # since it is a Right Tail test\n",
    "print(\"p-value = \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Since the calculated p-value is greater than α (0.05) we fail to reject  the null hypothesis, i.e. researcher's claim is invalid or NOT Statistically Significant***\n",
    "\n",
    "#### Example - 6\n",
    "A study showed that on an average women in a city had 1.48 kids. A researcher believes that the number is wrong. He surveys 128 women in the city and finds that on an average these women had 1.39 kids with standard deviation of 0.84 kids. At 90% Confidence Level, test the claim.\n",
    "\n",
    "    H-0: µ = 1.48 H-a: µ != 1.48   n = 128   x-bar = 1.39   s-dev = 0.84   C = 90% = 0.9. \n",
    "    \n",
    "    \n",
    "Let's calculate the z-score and p-value to test the hypothesis. It is a **Two Tail Test**. This is a Two Tailed Test, so critical value = (1 -c) /2 = 0.05\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score =  -0.10714285714285725\n",
      "p-value =  0.4573378238740764\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "x_bar = 1.39\n",
    "µ = 1.48\n",
    "s_dev = 0.84\n",
    "z_score = (x_bar - µ)/s_dev\n",
    "print(\"Z-score = \", z_score)\n",
    "p_value = stats.norm.cdf(z_score) # since it is a Two Tail test\n",
    "print(\"p-value = \",p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Since the calculated p-value is greater than α/2 (0.05) we fail to reject  the null hypothesis, i.e. researcher's claim is invalid or NOT Statistically Significant***\n",
    "\n",
    "#### Example - 7\n",
    "The government says the average weight of males is 162.9 pounds or greater. A researcher thinks this is too high. He does a study of 39 males and gets an average weight of 160.1 pounds with a standard deviation of 1.6 pounds. At 0.05 Significance Level, test the claim.\n",
    "\n",
    "    H-0: µ >= 162.9   H-a: µ < 162.9   n = 39    x-bar = 160.1    s-dev = 1.6   α = 0.05\n",
    "\n",
    "Let's calculate the z-score and p-value to test the hypothesis. It is a **Left Tail Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score =  -1.750000000000007\n",
      "p-value =  0.040059156863816475\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "x_bar = 160.1\n",
    "µ = 162.9\n",
    "s_dev = 1.6\n",
    "z_score = (x_bar - µ)/s_dev\n",
    "print(\"Z-score = \", z_score)\n",
    "p_value = stats.norm.cdf(z_score) # since it is a Left Tail test\n",
    "print(\"p-value = \",p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Since the calculated p-value is less than α (0.05) we reject  the null hypothesis, i.e. researcher's claim is valid or Statistically Significant***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Variance (ANOVA)\n",
    "\n",
    "\n",
    "## What is ANOVA\n",
    "ANOVA or Analysis of Variance is a set of statistical tests to test if there is a **significant** difference between the **means** of a set of samples. It tests if the means of various samples of data are (***statistically***) equal or not. ANOVA, in its simplest form, tests if at least one of the sample mean is significantly different from the means of other sample. It does not conclude if means of **more than one** samples are different from other sample means. Nor does it make **pair-wise** comparisons between the samples. More advanced form of ANOVA tests and helps researchers conclude these aspects of the data (we will not discuss those).\n",
    "\n",
    "An important fact to note that while we use ANOVA to test if the sample means differ significantly, we actually compare the **variances**. Hence the name **Analysis of Variance**.\n",
    "\n",
    "## What is this test for?\n",
    "The one-way analysis of variance (ANOVA) is used to determine whether there are any statistically significant differences between the means of three or more independent (unrelated) groups. This guide will provide a brief introduction to the one-way ANOVA, including the assumptions of the test and when you should use this test. If you are familiar with the one-way ANOVA, you can skip this guide and go straight to how to run this test in SPSS Statistics by clicking here.\n",
    "\n",
    "## What does this test do?\n",
    "The one-way ANOVA compares the means between the groups you are interested in and determines whether any of those means are statistically significantly different from each other. Specifically, it tests the **Null Hypothesis**:\n",
    "\n",
    "                                H-0: µ-0 = µ-1 = µ-2 ........µ-k\n",
    "\n",
    "where µ = group mean and k = number of groups. \n",
    "\n",
    "If, however, the one-way ANOVA returns a statistically significant result, we accept the **Alternative Hypothesis (HA)**, which is that there are **at least** one group mean that is statistically significantly different from each other group means.\n",
    "\n",
    "At this point, it is important to realize that the one-way ANOVA is an omnibus test statistic and cannot tell you which specific groups were statistically significantly different from each other, only that at least two groups were. To determine which specific groups differed from each other, you need to use a post hoc test. Post hoc tests are described later in this guide.\n",
    "\n",
    "## Some Definitions\n",
    "### Grand Mean\n",
    "The **Grand Mean**  of a set of multiple samples is the mean of all observations: every data point, divided by the joint sample size. The Grand Mean can be calculated by adding all the observations of all samples and then dividing the SUM by the **total** number pf observations.\n",
    "\n",
    "Alternatively, the Grand Mean can also be calculated by the first calculating the **Means** of each of the individual samples, then adding the **sample means** and dividing the SUM by the number of samples or **Groups**.\n",
    "\n",
    "The **number of observations** in each of the samples does **NOT** have to be the same. The calculation of Grand Mean and calculation of **Sum Square of Treatments** (Treatments are also called **Groups**) and **Mean Square of Treatments** (defined below) shows that these definitions take into consideration the **unequal** sizes of samples by taking a **weighted average** of the **sum of squares** in the calculation of **Mean Square of Treatments**.\n",
    "\n",
    "## Sum Square of Treatments (SST) and Mean Square of Treatments (MST)\n",
    "\n",
    "**Sum of Squares of Treatments (SST)** measures the varition **between** Groups/Treatments and is defined  as\n",
    "\n",
    "         SUM[ for sample-1( sample size * (Sample Mean - Grand-Mean)-Square) + \n",
    "              for sample-2( sample size * (Sample Mean - Grand-Mean)-Square) +\n",
    "              .....\n",
    "              for sample-k( sample size * (Sample Mean - Grand-Mean)-Square)]\n",
    "              \n",
    "       i.e. SUM[n1 * (mean1 - Grand-Mean)**2 + n2 * (mean2- Grand-Mean)**2 +...(nK * (meanK - Grand-Mean)**2]\n",
    "       \n",
    "Where \n",
    "       \n",
    "       n1, n2...nK are the sample sizes of the K Treatments or Groups\n",
    "       \n",
    "       mean1, mean2.....meanK are the means of each of the K samples\n",
    "       \n",
    "       Grand-Mean is the Grand Mean defined above\n",
    "       \n",
    "**Mean Square of Treatments (MST)** of **K** Treatments or Groups is defined as\n",
    "\n",
    "       SST/(K - 1)\n",
    "       \n",
    "## Degree of Freedom between Treatments/Groups\n",
    "The **Degree of Freedom** between **K** Treatments or Groups is defined as\n",
    "\n",
    "                 DF-between = (K - 1)\n",
    "\n",
    "## Sum of Square of Errors (SSE) and Mean Square of Errors (MSE)\n",
    "**Sum of Squares of Errors** measures the varition **within** Groups/Treatments and is defined  as\n",
    "\n",
    "      SUM [ (x1 - Sample-Mean)**2 + (x2 - Sample-Mean)**2 +.....(xn - Sample-Mean)**2]\n",
    "\n",
    "Where\n",
    "\n",
    "      x1, x2,...xn are the observations of the sample\n",
    "      n is the size of the sample\n",
    "      \n",
    "Using the above definition of **SSE**, we can see the **SSE** can also be defined as\n",
    "\n",
    "      SSE = (n - 1) * Sample Variance\n",
    "      \n",
    "**Mean Square of Errors (MSE)** of K samples with n-i observations in each is defined as\n",
    "     \n",
    "      SSE / (ni - 1)* K = SSE/ (ni * K - K) = SSE/ (N - K)\n",
    "      \n",
    "Where \n",
    "\n",
    "      ni is the size of the i-th sample\n",
    "      K is the number of groups/samples\n",
    "      N is \"Total\" number of observations i.e. SUM(ni) over K groups/samples\n",
    "      \n",
    "## Degree of Freedom within Group/Treatment\n",
    "**Degree of Freedom** within groups is defined for **K** groups with **ni** observations for each as \n",
    "\n",
    "      DF-within = K * (ni - 1) = (K * ni) - K = N - K\n",
    "      \n",
    "## F-Statistic for One Way ANOVA\n",
    "**F-Statistic** for One Way ANOVA is defined as\n",
    "\n",
    "     F-Statistic = MST/MSE\n",
    "     \n",
    "## p-value of One Way ANOVA\n",
    "One Way ANOVA uses the F-Statisctc (MST/MSE follow F-Distribution) as opposed to Z-Statistic (for Normal Distribution) as we saw the Hypothesis Testing in the previous section on **Hypothesis Testing** of samples with sample size of **30 or greater**.\n",
    "\n",
    "Statistical tables are available to get p-values from F-Statistic. One important point to note that ANOVA is ***always a Right Tail Test*** and hence is calculated, for hypothesis testing as ***(1 - p-value-from-table)***\n",
    "\n",
    "In our case we will use a the Python **cdf** function (for **F-Distribution**). In the section on Hypothesis Testing (for Normal Distribution) we used the **cdf** function for Normal Distribution.\n",
    "\n",
    "## One Way ANOVA Testing Steps\n",
    "Following the above definitions, the following are the steps of One Way ANOVA\n",
    "\n",
    "* Calculate the Grand Mean\n",
    "* Calculate the SST (between groups/treatments)\n",
    "* Calculate the MST (between groups/treatments)\n",
    "* Calculate the SSE (within groups/treatments)\n",
    "* Calculate the MSE (within groups/treatments)\n",
    "* Calculate F-Statistic = MST/MSE\n",
    "* Get the p-value from the F-Statistic\n",
    "* If the calculated p-value is **smaller** than the \"Required** Level of Significance, **Reject** the Null Hypothesis, (i.e. **at least one of the sample means significantly differ from other sample means**, otherwise **Fail to Reject** the Null Hypothesis (i.e. ***all the sample means are equal***)\n",
    "\n",
    "We will first do the One Way ANOVA manually (using spread sheet or calculator). Next we will do the same One Way ANOVA using the \"1-Factor ANOVA\" using Excel Analysis ToolPack and then will do the same using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18\n",
       "1    19\n",
       "2    20\n",
       "3    21\n",
       "4    22\n",
       "5    23\n",
       "6    18\n",
       "7    19\n",
       "8    20\n",
       "9    21\n",
       "Name: New York, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "anovadf = pd.read_csv(\"../../../CSV/anova-1way-csv.csv\")\n",
    "\n",
    "anovadf[\"New York\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New York</th>\n",
       "      <th>Texas</th>\n",
       "      <th>Oregon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   New York  Texas  Oregon\n",
       "0        18     18      21\n",
       "1        19     20      22\n",
       "2        20     16      17\n",
       "3        21     20      18\n",
       "4        22     21      22\n",
       "5        23     20      19\n",
       "6        18     18      21\n",
       "7        19     19      20\n",
       "8        20     17      18\n",
       "9        21     18      23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anovadf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=2.1025029797377845, pvalue=0.1417043469872377)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "stats.f_oneway(anovadf[\"New York\"], anovadf[\"Texas\"], anovadf[\"Oregon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1417044671120501"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5.488117768420701"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- stats.f.cdf(2.102502, 2, 27)\n",
    "\n",
    "stats.f.ppf(q=0.99, dfn= 2, dfd=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Groups</th>\n",
       "      <th>Count</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Average</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>10</td>\n",
       "      <td>201</td>\n",
       "      <td>20.1</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas</td>\n",
       "      <td>10</td>\n",
       "      <td>187</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>10</td>\n",
       "      <td>201</td>\n",
       "      <td>20.1</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Groups  Count  Sum  Average  Variance\n",
       "0  New York     10  201     20.1      2.77\n",
       "1     Texas     10  187     18.7      2.46\n",
       "2    Oregon     10  201     20.1      4.10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def mean(x):\n",
    "    return round((sum(x) / len(x)), 2)\n",
    "\n",
    "def diff_from_mean(x):\n",
    "    x_bar = mean(x)\n",
    "    return [round((x_i - x_bar), 2) for x_i in x]\n",
    "\n",
    "def sum_of_squares(x):\n",
    "    return round((sum(x_i**2 for x_i in x)), 2)\n",
    "\n",
    "def variance(x):\n",
    "    l = len(x) \n",
    "    deviations = diff_from_mean(x)\n",
    "    return round((sum_of_squares(deviations)/(l - 1)), 2)\n",
    "\n",
    "def calc_summary1(in_df):\n",
    "    i = 0\n",
    "    summary = []\n",
    "    while i < len(in_df.columns):\n",
    "        x = in_df[in_df.columns[i]]\n",
    "        name = x.name\n",
    "        gr_sum = sum(x)\n",
    "        gr_count = len(x)\n",
    "        gr_mean = mean(x)\n",
    "        deviation = diff_from_mean(x)\n",
    "        gr_variance = variance(x)\n",
    "        ss_within_gr = sum_of_squares(deviation)\n",
    "        summary.append({'Groups': name,'Count':gr_count, 'Sum': gr_sum, 'Average': gr_mean, 'Variance': gr_variance})\n",
    "        #ret_df = pd.DataFrame([])\n",
    "        #ret_df = ret_df.append(summary)\n",
    "        i += 1\n",
    "    ret_df = pd.DataFrame(summary)\n",
    "    ret_df = ret_df[['Groups', 'Count', 'Sum', 'Average', 'Variance']]\n",
    "    \n",
    "    return ret_df\n",
    "\n",
    "result_df1 = calc_summary1(anovadf)\n",
    "result_df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source of Variance</th>\n",
       "      <th>SST/SSE</th>\n",
       "      <th>MST/MSE</th>\n",
       "      <th>df</th>\n",
       "      <th>F_Statistics</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Between Groups</td>\n",
       "      <td>13.0667</td>\n",
       "      <td>6.5334</td>\n",
       "      <td>2</td>\n",
       "      <td>2.10253</td>\n",
       "      <td>0.141701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Within Groups</td>\n",
       "      <td>83.9000</td>\n",
       "      <td>3.1074</td>\n",
       "      <td>27</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source of Variance  SST/SSE  MST/MSE  df F_Statistics   p_value\n",
       "0     Between Groups  13.0667   6.5334   2      2.10253  0.141701\n",
       "1      Within Groups  83.9000   3.1074  27                       "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_sse_mse(in_df):\n",
    "    num_samples = 0\n",
    "    sse = 0\n",
    "    total_sample_size = 0\n",
    "    while num_samples < len(in_df.columns):\n",
    "        data = in_df[in_df.columns[num_samples]]\n",
    "        dev = diff_from_mean(data)\n",
    "        sse += sum_of_squares(dev)\n",
    "        total_sample_size += len(data)\n",
    "        num_samples += 1\n",
    "        mse = round(sse/(total_sample_size-num_samples), 4 )\n",
    "    #print('SSE = ', sse, 'Total Sample Size =', total_sample_size, 'MSE = ', mse)\n",
    "    return sse, mse, total_sample_size\n",
    "\n",
    "anova_sse, anova_mse, anova_sample_size = calc_sse_mse(anovadf)\n",
    "\n",
    "def grand_mean_df(in_df):\n",
    "    cum_mean = 0\n",
    "    num_groups = 0\n",
    "    while num_groups < len(in_df.columns):\n",
    "        cum_mean += mean (in_df[in_df.columns[num_groups]])\n",
    "        num_groups += 1\n",
    "    return round(cum_mean/num_groups, 4)\n",
    "\n",
    "def calc_sst_mst(in_df):\n",
    "    grand_mean = grand_mean_df(in_df)\n",
    "    num_groups = 0\n",
    "    sst = 0\n",
    "    while num_groups < len(in_df.columns):\n",
    "        data = in_df[in_df.columns[num_groups]]\n",
    "        sst +=  round(len(data) * (mean(data) - grand_mean)**2, 4)\n",
    "        num_groups += 1\n",
    "    mst = round(sst/(num_groups -1), 4)\n",
    "    return sst, mst, num_groups\n",
    "anova_sst, anova_mst, groups = calc_sst_mst(anovadf)\n",
    "\n",
    "def calc_summary_2(in_df):\n",
    "    anova_sst, anova_mst, groups = calc_sst_mst(anovadf)\n",
    "    anova_sse, anova_mse, anova_sample_size = calc_sse_mse(anovadf)\n",
    "    df_between = groups -1\n",
    "    df_within = anova_sample_size - groups\n",
    "    f_stats = anova_mst/anova_mse\n",
    "    p_value = 1- stats.f.cdf(f_stats, df_between, df_within)\n",
    "    summary = [{'Source of Variance': 'Between Groups', 'SST/SSE': anova_sst, 'df': df_between, 'MST/MSE': anova_mst,\n",
    "                 'F_Statistics': f_stats, 'p_value': p_value},\n",
    "               {'Source of Variance': 'Within Groups', 'SST/SSE': anova_sse, 'df': df_within, 'MST/MSE': anova_mse,\n",
    "                 'F_Statistics': '', 'p_value': ''}\n",
    "               ]\n",
    "    ret_df = pd.DataFrame(summary)\n",
    "    ret_df = ret_df[['Source of Variance', 'SST/SSE', 'MST/MSE', 'df', 'F_Statistics', 'p_value']]\n",
    "    return ret_df\n",
    "result_df = calc_summary_2(anovadf)\n",
    "result_df.head(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Groups</th>\n",
       "      <th>Count</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Average</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>10</td>\n",
       "      <td>201</td>\n",
       "      <td>20.1</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas</td>\n",
       "      <td>10</td>\n",
       "      <td>187</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>10</td>\n",
       "      <td>201</td>\n",
       "      <td>20.1</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Groups  Count  Sum  Average  Variance\n",
       "0  New York     10  201     20.1      2.77\n",
       "1     Texas     10  187     18.7      2.46\n",
       "2    Oregon     10  201     20.1      4.10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source of Variance</th>\n",
       "      <th>SST/SSE</th>\n",
       "      <th>MST/MSE</th>\n",
       "      <th>df</th>\n",
       "      <th>F_Statistics</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Between Groups</td>\n",
       "      <td>13.0667</td>\n",
       "      <td>6.5334</td>\n",
       "      <td>2</td>\n",
       "      <td>2.10253</td>\n",
       "      <td>0.141701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Within Groups</td>\n",
       "      <td>83.9000</td>\n",
       "      <td>3.1074</td>\n",
       "      <td>27</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source of Variance  SST/SSE  MST/MSE  df F_Statistics   p_value\n",
       "0     Between Groups  13.0667   6.5334   2      2.10253  0.141701\n",
       "1      Within Groups  83.9000   3.1074  27                       "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "def anova_1way(in_df):\n",
    "    ret_df1 = calc_summary1(in_df)\n",
    "    #result_df1.head(10)\n",
    "    ret_df2 = calc_summary_2(in_df)\n",
    "    #result_df2 = result_df2[['Source of Variance', 'SST/SSE', 'MST/MSE', 'df', 'F_Statistics', 'p_value']]\n",
    "    return ret_df1, ret_df2\n",
    "    \n",
    "res_df1, res_df2 = anova_1way(anovadf)\n",
    "res_df1.head(10)\n",
    "res_df2.head(10)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance, Correlation, Least Square Method in Regression Analysis\n",
    "### Covariance and Correlation Coefficient\n",
    "**Sample Covariance** measures the strength and the direction of the relationship between the elements of **two** samples. **Variance**, as defined before deals with **one** sample of data whereas **Covariance** measures how much and in what direction a variable change (***positive, negative or independent***) with the change of the second variable.\n",
    "\n",
    "***--> create math notations***\n",
    "\n",
    "**Covariance** of two samples of data [x1, x2...xi] and [y1, y2,...yi] is measured as\n",
    "\n",
    "**Cov(xy) = SUM((xi - x-bar)(yi - y-bar))/(n-1)** where\n",
    "\n",
    "xi, yi = The ith value of the two samples (x, y) of data\n",
    "\n",
    "x-bar, y-bar = Average of x-data sample and y-data sample\n",
    "\n",
    "n = sample size\n",
    "\n",
    "**Positive Covariance** means y-value increases as x-value increases. **Negative Covariance** means y-value decreases as x-value increases. **Zero Covariance (Covariance value zero or close to zero** means x-values and y-values are **Independent or Nearly Independent** of each other.\n",
    "\n",
    "**Sample Correlation**, also called **Correlation Coefficient** between data samples x and y is measured from the **Covariance** between x, y using the formula\n",
    "\n",
    "**r-xy = (S-xy)/ (sigma-x)(sigma-y)** where \n",
    "\n",
    "r-xy = Correlation Coefficient between x and y\n",
    "\n",
    "S-xy = Covariance between x, y\n",
    "\n",
    "sigma-x = Standard Deviation of x\n",
    "\n",
    "sigma-y = Standard Deviation of y\n",
    "\n",
    "**Correlation Coefficient** is **unit-less** and has values between -1 (perfect anti-correlation) and +1 (perfect correlation). \n",
    "\n",
    "Positive, negative and zero/near-zero **Correlation Coefficient** are interprted in the same way as positive, negative and zero/near-zero **Covariance**\n",
    "\n",
    "We will be using **Covariance, Correlation Coefficient** in details in **Regression Analysis (Predictive Analytics section)**. In **Regression Analysis** we will primarily use **Least Square** method of finding the best fit for the **Regression Line** through the data.\n",
    "\n",
    "We will discuss **Least Square Method** briefly here and in more details in **Regression Analysis (Predictive Analytics)** section.\n",
    "\n",
    "The **Covariance** and **Correlation Coefficient** of data samples can be calculated using Python as follows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n",
      "Covariance between x and y =  25.0\n",
      "===================================================\n",
      "Correlation between x and y =  1.0\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "x = [1, 2, 3, 4, 5]\n",
    "y = [10, 20, 30, 40, 50]\n",
    "\n",
    "def dot(v, w):\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "print(dot(x, y))\n",
    "\n",
    "def covariance(x, y):\n",
    "    n = len(x) # length of both x and y are required to be the same\n",
    "    return (dot(diff_from_mean(x), diff_from_mean(y)))/ (n-1)\n",
    "\n",
    "print('Covariance between x and y = ', covariance(x, y))\n",
    "print('===================================================')\n",
    "\n",
    "def correlation(x, y):\n",
    "    sdev_x = standard_deviation(x)\n",
    "    sdev_y = standard_deviation(y)\n",
    "    if sdev_x > 0 and sdev_y > 0:\n",
    "        return covariance(x,y)/(sdev_x * sdev_y)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "print('Correlation between x and y = ', correlation(x, y))\n",
    "print('===================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Square Method\n",
    "**Covariance** and **Correlation** are measures of linear association. In **Linear Regression**the first variable xi is ca\n",
    "lled the **explanatory or predictive** variable. The corresponding observation yi, taken from the input xi, is called the **response**. For example, can we explain or predict the **income of banks (response variable)** from its **assets (explanatory variable)**.\n",
    "\n",
    "In **Linear Regression**, the response variable is linearly related to the explanatory variable, but is subject to deviation\n",
    "or to **error**. So the relationship can be expressed as \n",
    "\n",
    "\n",
    "  **y-i = alpha + beta * x-i + error**\n",
    "  \n",
    "Our goal is, given the data, the x-i’s and y-i’s, to find the values of **alpha** and **beta** that will give the line having the best fit to the data. The principle of **Least Squares Regression** states that the best choice of this linear relationship is the one that minimizes the **square in the vertical distance (error)** from the y values in the data and the y values on the regression line. Thus, our problem of finding the **best fit** line translates to a **minimization** problem.\n",
    "\n",
    "This can be done with a small amount of calculus (\"Gradient Descent\", which we will **not do**). We will also have to note two important facts\n",
    "* ***With the best fit the error is always zero***\n",
    "* ***The best fit line passes through the point x-bar, y-bar***\n",
    "\n",
    "Skipping the calculus, the value of **beta** for the best fit (called **beta-hat**) is\n",
    "\n",
    "**beta-hat = Covariance(x,y) / Variance (x)**\n",
    "\n",
    "Also since the best fit line passes through (x-bar, y-bar), \n",
    "\n",
    "**y-bar = alpha-hat + beta-hat * x-bar + 0** (error = 0 for the best fit line)\n",
    "\n",
    "\n",
    "**alpha-hat = y-bar - beta-hat * x-bar**\n",
    "\n",
    "We have already created the Python functions for **Covariance(x,y) and Variance(x)**, **x-bar and y-bar***, and so we can easily calculate the value of **beta-hat** using those functions. Once **beta-hat** is calculated, **alpha-hat** can be calculated by substituting the values of **beta-hat, x-bar and y-bar**.\n",
    "\n",
    "We will get back to this subject in more details in the **Linear Regression (Predictive Analytics)** section.\n",
    "\n",
    "The discussion we have had so far is called **Simple Linear Regression** where the **dependent variable (response)** depnds on a **single** **independent (explanatory) variable**.\n",
    "\n",
    "We will also discuss the case of **Multiple Linear Regression** where the **dependent variable (response)** depnds on **multiple independent (explanatory) variables**.\n",
    "\n",
    "A third method of regression called the **Logistic Regression** will also be dicussed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability, Conditional Probability, Bayes' Theorem\n",
    "## Conditional Probability\n",
    "**Conditional Probability is defined as the probability of an event ( A ), given that another ( B ) has already occurred.**\n",
    "\n",
    "If events A and B are not independent, then the probability of the intersection of A and B (the probability that both P(B|A) = vents occur) is defined by \n",
    "P(A and B) = P(A)P(B|A).\n",
    "\n",
    "From this definition, the conditional probability P(B|A) is easily obtained by dividing by P(A):\n",
    "\n",
    "**P(B|A) = P(B and A) / P(A)**\n",
    "\n",
    "In the Predictive Analytics section we will learn a very widely used **Classification** algorithm called the **Naive Bayes Classifiaction Algorithm**.\n",
    "\n",
    "It is a Machine Learning algorithm that is often used in data sets with multiple attributes. It is very easy to calculate and hence is often used to classify things in real time, such as \"if an email containing a set of key words is classified as spam\", \"a newly published article belongs to a class of articles\", \"if an insurance claim, just submitted is real or fraud\" etc.\n",
    "\n",
    "The **Bayes** part of the name comes from Thomas Bayes, the inventor of the foundational Bayes' theorem and the **Naive** part of the name comes from the assumption that the factors guiding the occurrance of an event are **independent** of each other, even though in real life, they may not be so (a somewhat **naive** assumption). However, this algorithm produces very good/reliable results and is widely used.\n",
    "\n",
    "\n",
    "\n",
    "## Bayes' Theorem\n",
    "Bayes' Theorem (also called Bayes' Law or Bayes' Formula) is stated as\n",
    "\n",
    "***Probability of an event B given that an event A has occurred, is equal to the probability of B given A has occurred multiplied by the probability of A given B has occurred divided by the probability of B***\n",
    "\n",
    "***P(A|B) = (P(B|A) X P(A))/P(B)***\n",
    "\n",
    "where\n",
    "\n",
    "P(A|B) = Probability of event A given the event B has occurred\n",
    "\n",
    "P(B|A) = Probability of event B given the event A has occurred\n",
    "\n",
    "P(A), P(B) = Probabilities of event A and B respectively\n",
    "\n",
    "### Commonly used terms in Bayesian Classification\n",
    "A is called the **Proposition** and B is called the **Evidence**\n",
    "\n",
    "P(A) is called the **Prior Probability of Proposition** and P(B) is called the **Prior probability of Evidence**\n",
    "\n",
    "P(A|B) is called the **Posterior**\n",
    "\n",
    "P(B|A) is called the **Likelyhood**\n",
    "\n",
    "\n",
    "In other words\n",
    "\n",
    "***Posterior = (Likelihood X Prior Probability of Proposition)/Prior Probability of Evidence***\n",
    "\n",
    "### Bayesian Theorem as applied to Naive Bayes Algorithm\n",
    "In Machine Learning classification there are multiple clesses C1, C2, C3...and each class with multiple features x1, x2, x3...(e.g. an insurance claim is in class 'Valid' or 'Fraud' and each claim has features such as 'amount of claim', 'doctor submitting the claim', 'amount of the claim', 'frequency of high value claim for same treatment by the same doctor' etc.). The aim of the algorithm is to determine the **Conditional Probability** of an object (an insurance claim) with features x1, x2,...xn belonging to a class Ci.\n",
    "\n",
    "We will learn Bayesin Classification and it's calculation (using Python) in much more details in the **Predictive Analytics** section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
